{"model_type": "lstm", "ninp": 400, "nhid": 2048, "nlayers": 3, "tie_encoder_decoder": false, "dropout": 0.1, "lr": 0.001, "num_warmup_steps": 0, "batch_size": 64, "accumulate_grad_batches": 1, "bptt": 140}