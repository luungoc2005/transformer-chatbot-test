{"model_type": "transformer", "ninp": 256, "nhid": 1024, "nlayers": 6, "nhead": 8, "dropout": 0.1, "tie_encoder_decoder": false, "lr": 0.0003, "num_warmup_steps": 8000, "batch_size": 64, "accumulate_grad_batches": 1, "bptt": 160}